{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 2: Quadro K4000 (CNMeM is disabled, cuDNN 5005)\n",
      "../../../../Code/keras-1/keras/backend/theano_backend.py:989: UserWarning: ['filters_dilations'] are now deprecated in `tensor.nnet.abstract_conv.conv2d` interface and will be ignored.\n",
      "  filter_shape=filter_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../../DataSet/Com_Det/85-7696_s2_02.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4ae903ea66cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmatrefresh\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m        \u001b[0mMatinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStruExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetMatinfo_volume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# call this function to generate nece info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m        \u001b[1;31m#dd.io.save(matpath, Matinfo, compression='zlib')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/OwnCloud/WorkStation/fullyConv/code/proj_utils/Extractor.pyc\u001b[0m in \u001b[0;36mgetMatinfo_volume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mImageGenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetImageGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimgindx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/OwnCloud/WorkStation/fullyConv/code/proj_utils/ImageGenerator.pyc\u001b[0m in \u001b[0;36myieldImages\u001b[1;34m(myobj)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m#print('start mask')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[0mprocess_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_process_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontour_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_org\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresizeratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresizeratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[1;31m#print('end mask')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mmask_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/OwnCloud/WorkStation/fullyConv/code/proj_utils/ImageGenerator.pyc\u001b[0m in \u001b[0;36mprocess_mask_with_weight\u001b[1;34m(myobj, contour_mat, mask_shape, resizeratio)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m  \u001b[0mmyobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mfilled_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilled_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[0mfilled_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilled_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/local/anaconda2/lib/python2.7/site-packages/skimage/morphology/misc.pyc\u001b[0m in \u001b[0;36mfunc_out\u001b[1;34m(image, selem, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mselem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mselem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_selem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/local/anaconda2/lib/python2.7/site-packages/skimage/morphology/binary.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[1;34m(image, selem, out)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mndi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/local/anaconda2/lib/python2.7/site-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36mbinary_dilation\u001b[1;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     return _binary_erosion(input, structure, iterations, mask,\n\u001b[1;32m--> 502\u001b[1;33m                            output, border_value, origin, 1, brute_force)\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuanpuxie/local/anaconda2/lib/python2.7/site-packages/scipy/ndimage/morphology.pyc\u001b[0m in \u001b[0;36m_binary_erosion\u001b[1;34m(input, structure, iterations, mask, output, border_value, origin, invert, brute_force)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         _nd_image.binary_erosion(input, structure, mask, output,\n\u001b[1;32m--> 248\u001b[1;33m                                      border_value, origin, invert, cit, 0)\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcit\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbrute_force\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "#os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu2,optimizer=fast_run,force_device=True, allow_gc=False'\n",
    "cloudRoot  = os.path.join('..','..','..','..')\n",
    "projroot = os.path.join('..','..')\n",
    "home = os.path.join(cloudRoot, '..')\n",
    "\n",
    "dataroot = os.path.join(cloudRoot,'DataSet','Mixture_DataSets')\n",
    "\n",
    "#dataroot = os.path.join(projroot, 'Data')\n",
    "modelroot = os.path.join(projroot, 'Data')\n",
    "\n",
    "dataroot = os.path.join(projroot, 'Data')\n",
    "trainingset = 'Com_Det' \n",
    "modelsubfolder = 'deep_det_fcn'\n",
    "modelfolder = os.path.join(dataroot, 'Model',trainingset,modelsubfolder)\n",
    "#trainingimagefolder = os.path.join(dataroot,'TrainingData', trainingset)\n",
    "trainingimagefolder = os.path.join(home,'DataSet', trainingset)\n",
    "\n",
    "\n",
    "kerasversion = 'keras-1'\n",
    "#kerasversion = 'keras_classical'\n",
    "sys.path.insert(0, os.path.join(cloudRoot, 'Code', kerasversion))\n",
    "sys.path.insert(0, os.path.join(cloudRoot, 'Code', kerasversion,'keras'))\n",
    "sys.path.insert(0, os.path.join(cloudRoot, 'Code', kerasversion,'keras','layers'))\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, os.path.join('..', 'proj_utils') )\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import deepdish as dd\n",
    "\n",
    "from train_eng import get_mean_std\n",
    "from proj_utils.local_utils import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from Extractor import FcnExtractor\n",
    "from keras.utils import  generic_utils\n",
    "from kerasOneModel import buildCellSegModel as buildmodel\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "from loss_fun import weighted_loss\n",
    "from proj_utils.keras_utils import elu\n",
    "activ = elu(alpha=1.0)\n",
    "last_activ = 'relu'  \n",
    "\n",
    "if  __name__ == '__main__':\n",
    "    \n",
    "    #loss = weighted_loss(base = 'se')\n",
    "    #use_weighted = 1    #means you have a weight mask in the last dimension of mask\n",
    "    loss = 'mse'\n",
    "    use_weighted = 0    #means you have a weight mask in the last dimension of mask\n",
    "\n",
    "    # for build the model    \n",
    "    img_channels = 3    \n",
    "    lr = 0.003\n",
    "    weight_decay = 1e-6\n",
    "    \n",
    "    patchsize = 200\n",
    "    labelpatchsize = 200\n",
    "    label_channels = 2\n",
    "    classparams = {}\n",
    "    classparams['patchsize']   = patchsize\n",
    "    classparams['labelpatchsize']   = labelpatchsize\n",
    "    classparams['channel'] = img_channels\n",
    "    classparams['label_channel'] = label_channels  # one for mask and last dimension is for weight mask\n",
    "    classparams['ImageGenerator_Identifier'] =  'process_mask_with_weight' #'process_contour_cellcounting' # 'process_cell_mask'\n",
    "    # the following is for Image generator parameters\n",
    "    decayparam = {}\n",
    "    decayparam['alpha'] = 3\n",
    "    decayparam['r'] = 3\n",
    "    decayparam['scale'] = 5\n",
    "    decayparam['decalratio'] = 0.5\n",
    "    decayparam['smallweight'] = 0.05\n",
    "    decayparam['use_gauss'] = 1\n",
    "\n",
    "    classparams['decayparam'] = decayparam\n",
    "    classparams['w'] = 10 # weight wrt distance\n",
    "    classparams['wc'] = 1 # weight wrt to class\n",
    "    classparams['dilate'] = 8\n",
    "\n",
    "    classparams['datadir'] = trainingimagefolder\n",
    "    classparams['volume'] = 2\n",
    "    classparams['dataExt'] = ['.png','.tif','jpg']             # the data ext\n",
    "    classparams['labelExt']    = ['.mat']          # the label ext\n",
    "    classparams['contourname']   = 'Contours'      # the contour name in the cell array\n",
    "    classparams['labelSuffix']  = [\"\",'_withcontour', '_gt','_seg'] # the suffix of label\n",
    "\n",
    "    # classparams['datadir'] = trainingimagefolder\n",
    "    # classparams['ImgExt'] = ['.bmp']\n",
    "    # classparams['gt_folder']  = 'gt_perimysium'\n",
    "    # classparams['LabelExt']  = ['.mat']\n",
    "    # classparams['contourext']  = ['']\n",
    "    # classparams['contourname']   = 'paramesium'\n",
    "    # classparams['volume'] = 'paramesium'\n",
    "    # classparams['contourname']   = 'paramesium'\n",
    "    classparams['maxsamples']  = 1280000\n",
    "    #classparams['usecontour']  = 0\n",
    "    #classparams['dialate']     = 1\n",
    "    classparams['usingindx']     = 1\n",
    "    #classparams['padsize']     = labelpatchsize\n",
    "    classparams['pickratio']   = 0.005  # 1 means take all the pixel\n",
    "    classparams['crop_patch_size']   =  None #(0.95,0.95)\n",
    "    classparams['selected_portion']   = 0.01  # 1 means take all the islet pixels\n",
    "    #classparams['selected_num']   = 100  # how many patches you wanna take\n",
    "    classparams['mask_dilate'] = 30\n",
    "    classparams['resizeratio'] =  [1]  #[1, 0.7]\n",
    "    classparams['rotatepool']  = [0] #[0,90]\n",
    "    #classparams['step']  = labelpatchsize\n",
    "    #classparams['mode'] = 'grid'\n",
    "    classparams['maximg'] = -1\n",
    "    classparams['mask_thresh'] = 50\n",
    "    classparams['mask_prob'] =0.1\n",
    "    classparams['maxpatch'] = 100\n",
    "    classparams['random_pick'] =  True # if you wanna random pick\n",
    "    \n",
    "    StruExtractor = FcnExtractor(classparams)\n",
    "    nb_class   = classparams['labelpatchsize']  ** 2\n",
    "    \n",
    "    \n",
    "    batch_size = 16\n",
    "    meanstd = 0   # it is important to set this as 0 for FCN\n",
    "    chunknum = int(1280)\n",
    "    maxepoch = 1280\n",
    "    matrefresh = 2\n",
    "    meanstdrefresh = 1\n",
    "    refershfreq = 10\n",
    "    savefre = 1  # np.mod(chunidx, savefre) == 0:\n",
    "\n",
    "    rebuildmodel = 1\n",
    "    reuseweigths = 1\n",
    "    show_progress = 0 #if you want to show the testing cases.\n",
    "    if not os.path.exists(modelfolder):\n",
    "        os.makedirs(modelfolder)\n",
    "    modelDict = {}\n",
    "    modelpath = os.path.join(modelfolder, 'strumodel.h5') #should include model and other parameters\n",
    "    weightspath = os.path.join(modelfolder,'weights.h5')\n",
    "    arctecurepath = os.path.join(modelfolder,'arc.json')\n",
    "    matpath = os.path.join(modelfolder,'matinfo.h5')\n",
    "    meanstdpath = os.path.join(modelfolder, 'meanstd.h5')\n",
    "    paramspath = os.path.join(modelfolder, 'params.h5')\n",
    "    \n",
    "    if not os.path.isfile(arctecurepath) or  rebuildmodel == 1:\n",
    "       strumodel = buildmodel(img_channels,lr = lr, loss = loss, activ=activ, last_activ='relu')\n",
    "       if reuseweigths == 1 and os.path.isfile(weightspath):\n",
    "          strumodel.load_weights(weightspath)\n",
    "          # import h5py\n",
    "          # f = h5py.File(weightspath, mode='r')\n",
    "          # g = f['graph']\n",
    "          # weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "          # strumodel.set_weights(weights)\n",
    "          # f.close()\n",
    "    else:\n",
    "       #strumodel = dd.io.load(modelpath)['model']\n",
    "       strumodel = model_from_json(open(arctecurepath).read())\n",
    "       strumodel.load_weights(weightspath)\n",
    "    \n",
    "    \n",
    "    if not os.path.isfile(matpath) or matrefresh == 1:\n",
    "       Matinfo = StruExtractor.getMatinfo_volume() # call this function to generate nece info\n",
    "       #dd.io.save(matpath, Matinfo, compression='zlib')\n",
    "    else:\n",
    "       Matinfo = dd.io.load(matpath)\n",
    "       StruExtractor.setMatinfo(Matinfo)\n",
    "    datainfo = Matinfo['datainfo']\n",
    "\n",
    "    meanstdDic = {}\n",
    "    if not os.path.isfile(meanstdpath) or meanstdrefresh == 1:\n",
    "       thismean, thisdev = get_mean_std(StruExtractor, meanstd)\n",
    "       meanstdDic['thismean'] = thismean\n",
    "       meanstdDic['thisdev'] = thisdev\n",
    "       dd.io.save(meanstdpath, meanstdDic, compression='zlib')\n",
    "    else:\n",
    "       meanstdDic = dd.io.load(meanstdpath)\n",
    "       thismean = meanstdDic['thismean']\n",
    "       thisdev = meanstdDic['thisdev']\n",
    "\n",
    "\n",
    "    thisbatch = np.zeros((chunknum,datainfo['inputdim']))\n",
    "    thislabel = np.zeros((chunknum,datainfo['outputdim']))\n",
    " \n",
    "    print('finish compiling!')\n",
    "\n",
    "    for epochNumber in range(maxepoch):\n",
    "\n",
    "        if np.mod(epochNumber+1, refershfreq) == 0:\n",
    "                Matinfo = StruExtractor.getMatinfo_volume() # call this function to generate nece info\n",
    "                thismean, thisdev = get_mean_std(StruExtractor, meanstd)\n",
    "                datainfo = Matinfo['datainfo']\n",
    "        Totalnum = datainfo['Totalnum']\n",
    "        totalIndx = np.random.permutation(np.arange(Totalnum))\n",
    "\n",
    "        numberofchunk = (Totalnum + chunknum - 1)// chunknum   # the floor\n",
    "        chunkstart = 0\n",
    "        progbar = generic_utils.Progbar(Totalnum)\n",
    "        for chunkidx in range(numberofchunk):\n",
    "                thisnum = min(chunknum, Totalnum - chunkidx*chunknum)\n",
    "                thisInd = totalIndx[chunkstart: chunkstart + thisnum]\n",
    "                StruExtractor.getOneDataBatch_stru(thisInd, thisbatch[0:thisnum,:], thislabel[0:thisnum,:])\n",
    "                chunkstart += thisnum\n",
    "                BatchData = thisbatch[0:thisnum,:].astype(K.FLOATX)\n",
    "                BatchLabel = thislabel[0:thisnum,:].astype(K.FLOATX)\n",
    "\n",
    "                if nb_class == 2 and  labelpatchsize == 1:\n",
    "                    BatchLabel = np.concatenate([BatchLabel, 1- BatchLabel], axis = -1)\n",
    "\n",
    "                #---------------Train your model here using BatchData------------------\n",
    "                BatchData -= thismean\n",
    "                BatchData /= thisdev\n",
    "\n",
    "                BatchData = np.reshape(BatchData, (-1,patchsize, patchsize, img_channels ))\n",
    "\n",
    "                BatchLabel = np.reshape(BatchLabel, (-1,patchsize, patchsize, label_channels ))\n",
    "\n",
    "                BatchLabel = np.transpose(BatchLabel, (0, 3,1,2))\n",
    "\n",
    "                BatchData = np.transpose(BatchData, (0, 3,1,2))\n",
    "                \n",
    "\n",
    "                print('Training--Epoch--%d----chunkId--%d', (epochNumber, chunkidx))\n",
    "\n",
    "                for X_batch, Y_batch in dataflow(BatchData, BatchLabel, batch_size ):\n",
    "                    if use_weighted == 0:\n",
    "                        loss = strumodel.train_on_batch({'input': X_batch},{'output_mask': Y_batch[:,0:-1,:,:]})\n",
    "                    else:\n",
    "                        loss = strumodel.train_on_batch({'input': X_batch}, {'output_mask': Y_batch})\n",
    "                    if type(loss) == list:\n",
    "                        loss = loss[0]\n",
    "                    assert not np.isnan(loss) ,\"nan error\"\n",
    "                progbar.add(BatchData.shape[0], values = [(\"train loss\", loss)])\n",
    "\n",
    "                if np.mod(chunkidx, savefre) == 0:\n",
    "                    json_string = strumodel.to_json()\n",
    "                    open(arctecurepath, 'w').write(json_string)\n",
    "                    strumodel.save_weights(weightspath,overwrite = 1)\n",
    "                ndim = 1\n",
    "                if show_progress == 1:\n",
    "                    testingbatch = BatchData[ndim:ndim+1,...]\n",
    "                    if use_weighted == 1:\n",
    "                        testinglabel = strumodel.predict({'input': testingbatch})[0][0,:,:]\n",
    "                        testingTrue = np.reshape(BatchLabel[1,...],(label_channels, labelpatchsize, labelpatchsize))[0,:,:]\n",
    "                    else:\n",
    "                        testinglabel = strumodel.predict({'input': testingbatch})[0]\n",
    "                        testingTrue = np.reshape(BatchLabel[1,...], (label_channels, labelpatchsize, labelpatchsize) )[0,:,:]\n",
    "\n",
    "                    plt.subplot(1,3,1)\n",
    "                    plt.imshow(np.reshape(testingTrue,(labelpatchsize, labelpatchsize)))\n",
    "                    plt.subplot(1,3,2)\n",
    "                    plt.imshow(np.reshape(testinglabel,(labelpatchsize, labelpatchsize)))\n",
    "                    plt.subplot(1,3,3)\n",
    "                    plt.imshow(testingbatch[0,1,...])\n",
    "                    plt.show()\n",
    "\n",
    "        strumodel.save_weights(weightspath,overwrite = 1)\n",
    "        dd.io.save(paramspath, classparams, compression='zlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
